---
title: "Insurance Cross-Sell Model"
author: "T3 - Linear Boost"
date: "`r Sys.Date()`"
output:
  html_document:
  code_folding: hide
number_sections: true
toc: yes
toc_float: yes
pdf_document:
  toc: yes
toc_depth: '3'
---

```{r init, include=F}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
# Once installed, load the library.
library(ezids)
library(tidyverse)
library(corrplot)
library("ggplot2")
library(dplyr) 
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

SMART Problem?
Whether a customer would be interested in an additional insurance service like vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimize its business model and revenue. We have following information to assist our analysis: demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.

## Cross-Sell RAW Data

```{r cross-sell RAW Data, echo=FALSE, warning=FALSE}

vehicle<-read.csv("train.csv")

str(vehicle)

```

## EDA

```{r Data Distribution}

xkabledply(summary(vehicle))

paste0("We will be able to get a idea on the outliers here by the percentiles ( In the Annual_Premium the 3rd quartile is 39400 and the max is 540165 this represents the outliers in this column)")

```

## Response Variable Trend
```{r , echo=FALSE, message=FALSE, warning=FALSE}

vehicle %>% ggplot(aes(x=as.factor(Response))) +geom_bar(stat = "count") + ggtitle("Response Variable Count")

table(vehicle$Response)/dim(vehicle)[1]  # 12.26%

paste0("From the plot we can say that there's imbalance in response. The individuals interested in purchasing a vehicle insurance are only 12.6%.")
```


## Converting character variables into numerical for correlation
```{r , echo=FALSE, message=FALSE, warning=FALSE}

# Assign integer values to character variables

vehicle$Gender <- ifelse(vehicle$Gender == 'Male', 0,1)

vehicle$Vehicle_Damage <- ifelse(vehicle$Vehicle_Damage == 'Yes', 1,0)

vehicle$Vehicle_Age <- ifelse(vehicle$Vehicle_Age == '> 2 Years', 2,ifelse(vehicle$Vehicle_Age == '1-2 Year', 1, 0))

#vehicle.cor= cor(vehicle[,c(3,4,5,6,9,10,11,12)])
vehicle.cor= cor(vehicle)
xkabledply(vehicle.cor)

corrplot(vehicle.cor, method = "number", type="upper", col=NULL, title="Vehicle Correlation", use="pairwise.complete.obs")
#
```

## Converting categorical variables into factors
```{r , echo=FALSE, message=FALSE, warning=FALSE}

vehicle$Region_Code <-ifelse(vehicle$Region_Code %in% c(9,23,25,33,44,50,34,36,42), 1, # "Northeast" 
                             ifelse(vehicle$Region_Code %in% c(18,17,26,39,55,19,20,27,29,31,38,46), 2, #"Midwest"
                                    ifelse(vehicle$Region_Code %in% c(10,11,12,13,24,37,45,51,54,1,21,28,47,5,22,40,48), 3, #"South"
                                           ifelse(vehicle$Region_Code %in% c(4,8,16,35,30,49,32,56,2,6,15,41,53),4,5)))) # "West","Hogwarts"

vehicle_xgb <- vehicle

vehicle$Gender <- factor(vehicle$Gender)
vehicle$Driving_License <- factor(vehicle$Driving_License)
vehicle$Previously_Insured <- factor(vehicle$Previously_Insured)
vehicle$Vehicle_Damage <- factor(vehicle$Vehicle_Damage)
vehicle$Vehicle_Age <- factor(vehicle$Vehicle_Age)

vehicle$Region_Code <- factor(vehicle$Region_Code)

corrplot(cor (vehicle[c(3,9,10,11,12)]), method = "number", type="upper", col=NULL)

vehicle$Response <- factor(vehicle$Response)

```

```{r , echo=FALSE, message=FALSE, warning=FALSE}

library(ROSE)

vehicle <- ovun.sample(Response ~ ., data = vehicle, method = "over",N = 668798)$data

vehicle_xgb <- ovun.sample(Response ~ ., data = vehicle_xgb, method = "over",N = 668798)$data

# vehicle <- ovun.sample(Response ~ ., data = vehicle, method = "under", N = 93420)$data
# 
# vehicle_xgb <- ovun.sample(Response ~ ., data = vehicle_xgb, method = "under", N = 93420)$data


```

```{r}
loadPkg("leaps")

regnonlin.forward10 <- regsubsets(Response ~ ., data = vehicle, nvmax = 10, method = "exhaustive")  
# leaps, regsubsets: Model selection by exhaustive search, forward or backward stepwise, or sequential replacement
#The plot will show the Adjust R^2 when using the variables across the bottom
plot(regnonlin.forward10, scale = "adjr2", main = "Adjusted R^2")
plot(regnonlin.forward10, scale = "bic", main = "BIC")
plot(regnonlin.forward10, scale = "Cp", main = "Cp")
summary(regnonlin.forward10)
```


```{r , echo=FALSE, message=FALSE, warning=FALSE}

mod1 <- glm(Response ~ Vehicle_Age + Vehicle_Damage, data = vehicle, binomial(link = "logit"))

summary(mod1)

expcoeff = exp(coef(mod1))

```
All the coefficients are found significant (small p-values). All features have a positive effect on customer response. These are reasonable results and confirms our common beliefs.  

We can also easily obtain the growth/decay factors for each variable. Notice that these factors apply to the odds-ratio, not the odds of being accepted. Nonetheless, these growth and decay factors are very useful in our analysis. The factors are the exponential of the coefficients:  

```{r growthDecayFactors2, results='markup', collapse=F}

expcoeff = exp(coef(mod1))

xkabledply( as.table(expcoeff), title = "Exponential of coefficients of regression model" )

```

From these results, we can say, for example:

* The effect of having a vehicle for 1 to 2 years, compared to less than 1 year, is boosting by a factor of `r format(expcoeff[2],digit=4)`, for the log(odds-ratio).  Any factor less than 1 represents a negative effect.
* The effect of having a vehicle for more than 2 years, compared to less than 1 year, is boosting even more, by a factor of `r format(expcoeff[3],digit=4)`, again, for the log(odds-ratio).  
* Customers with vehicle damage are likely to respond more, by a factor of `r format(expcoeff[4],digit=4)`, again, for the log(odds-ratio). 

**Deviance Evaluation**

Degree of Freedom for Null Deviance is set to 713 and for Residual Deviance is set to 710.

```{r Deviance Evaluation, echo=TRUE}

summary_mod1 <- summary(mod1)

paste0(ifelse(pchisq(summary_mod1$null.deviance, nrow(vehicle)-1, lower.tail=F) < 0.05,
              ifelse(pchisq(summary_mod1$deviance, nrow(vehicle)-4, lower.tail=F) < 0.05, "Model is not a good fit","Model is a good fit")
              ,"Model is a good fit"))


```
**Confusion Matrix**

```{r Confusion Matrix, echo=TRUE}

loadPkg("regclass")

xkabledply( confusion_matrix(mod1), title = "Confusion matrix from Logit Model" )

unloadPkg("regclass")

paste0 ("Accuracy of the model is ",round((26295 + 45728)/93420 * 100,2), "%. But since we have an unbalanced data, Confusion Matrix won't be the best metric")

```
**Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC)**

```{r roc_auc}
loadPkg("pROC") 
prob <- predict(mod1, type = "response" )
vehicle$prob<- prob
h <- roc(Response~prob, data=vehicle)
auc(h) # area-under-curve prefer 0.8 or higher.
plot(h)

unloadPkg("pROC")

paste0("Area under the curve is greater than 80% which indicates that the model is a good fit.")

```



```{r , echo=FALSE, message=FALSE, warning=FALSE}

n = nrow(vehicle)

label = as.integer(vehicle$Response)-1

train.index=sample(1:n,size=round(n*0.70),replace=FALSE)
train.data=vehicle[train.index,]
train.label = label[train.index]
test.data = vehicle[-train.index,]
test.label = label[-train.index]


library(class)
vehicle_pred <- knn(train = train.data, test = test.data, cl=train.label, k=50)
tb <- table(vehicle_pred,test.label)
accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tb)

```

```{r , echo=FALSE, message=FALSE, warning=FALSE}
library(xgboost)

vehicle_xgb$Response <- factor(vehicle_xgb$Response)

# Convert the Species factor to an integer class starting at 0
# This is picky, but it's a requirement for XGBoost
species = vehicle_xgb$Response
label = as.integer(vehicle_xgb$Response)-1
vehicle_xgb$Response = NULL

n = nrow(vehicle_xgb)
train.index = sample(n,floor(0.75*n))
train.data = as.matrix(vehicle_xgb[train.index,])
train.label = label[train.index]
test.data = as.matrix(vehicle_xgb[-train.index,])
test.label = label[-train.index]

# Transform the two data sets into xgb.Matrix
xgb.train = xgb.DMatrix(data=train.data,label=train.label)
xgb.test = xgb.DMatrix(data=test.data,label=test.label)

num_class = length(levels(species))
params = list(
  booster="gbtree",
  eta=0.1,
  max_depth=10,
  gamma=3,
  subsample=0.75,
  colsample_bytree=0.75,
  objective="multi:softprob",
  eval_metric="merror",
  num_class=num_class
)


# Train the XGBoost classifer
xgb.fit=xgb.train(
  params=params,
  data=xgb.train,
  nrounds=500,
  nthreads=1,
  early_stopping_rounds=10,
  watchlist=list(val1=xgb.train,val2=xgb.test),
  verbose=0
)

# Review the final model and results
xgb.fit

xgb.pred = predict(xgb.fit,test.data,reshape=T)
xgb.pred = as.data.frame(xgb.pred)
colnames(xgb.pred) = levels(species)

xgb.pred$prediction = apply(xgb.pred,1,function(x) colnames(xgb.pred)[which.max(x)])
xgb.pred$label = levels(species)[test.label+1]

# Calculate the final accuracy
result = sum(xgb.pred$prediction==xgb.pred$label)/nrow(xgb.pred)
print(paste("Final Accuracy =",sprintf("%1.2f%%", 100*result)))

```


```{r , echo=FALSE, message=FALSE, warning=FALSE}

library(randomForest)

n = nrow(vehicle)
train.index = sample(n,floor(0.75*n))
train.data = as.matrix(vehicle_xgb[train.index,])
train.label = label[train.index]
test.data = as.matrix(vehicle_xgb[-train.index,])
test.label = label[-train.index]


# train <- sample(nrow(vehicle), 0.7*nrow(vehicle), replace = FALSE)
# TrainSet <- vehicle[train,]
# ValidSet <- vehicle[-train,]

rf <- randomForest(Response ~ ., data = vehicle, proximity=FALSE)


summary(rf)

# Predicting on train set
predTrain <- predict(rf, train.data, type = "Response")

table(predTrain, vehicle$Response)

predValid <- predict(rf, test.data, type = "Response")

# Checking classification accuracy
mean(predValid == ValidSet$Response)                    
table(predValid,test.data$Response)


```

**Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC)**

```{r RFroc_auc}
loadPkg("regclass")

xkabledply( confusion_matrix(rf), title = "Confusion matrix from Logit Model" )

unloadPkg("regclass")

paste0 ("Accuracy of the model is ",round((344 + 152)/714 * 100,2), "%. But since we have an unbalanced data, Confusion Matrix won't be the best metric")
```

```{r , echo=FALSE, message=FALSE, warning=FALSE}

control <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
algorithmList <- c('xgb.fit', 'mod1', 'glm', 'knn', 'svmRadial')
set.seed(seed)
models <- caretList(Class~., data=dataset, trControl=control, methodList=algorithmList)
results <- resamples(models)
summary(results)
dotplot(results)


```
